Project Name: Image Captioning System To Assist The Blind
============================================================
The project is aimed at developing a system using deep learning techniques to assist visually impaired individuals in obtaining information by describing images taken by them.

Primary Goal
============
The primary goal of the project is to develop a system using deep learning techniques to assist visually impaired individuals in obtaining information by describing images taken by them. The system uses a CNN model and an NLP model to create a single image captioning system that takes image features as input and generates a text sequence describing the image.

Outcome(s)
============
Incorporated state-of-the-art pre-trained models, such as ResNet50, VGG16, and VGG19, for image feature extraction and LSTM and Bidirectional LSTM for text generation. Evaluated various models to determine the best-performing model with a BLEU-score of 0.61 and deployed it using Flask and pyttsx3 for web and text-to-speech functionality in the app.

Screenshots
============
Dataset Split
-----------
![Dataset Design](/screenshots/Dataset-design.png)

Model Anatomy
-----------
![Model Anatomy](/screenshots/Model-Anatomy.png)

Project Workflow
-----------
![Project Workflow](/screenshots/Project-workflow.png)

Results
-------
![Results Table](/screenshots/Results.png)


Final Outcome
-----------
![Home Interface](/screenshots/homeint.png)
![Browse](/screenshots/browse.png)
![Selected](/screenshots/selected.png)
![Choice](/screenshots/choice.png)
![Generating](/screenshots/generating.png)
![Generated](/screenshots/generated.png)

Additional Outputs
------------------
![Output1](/screenshots/output1.png)
![Output2](/screenshots/output2.png)

